{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import pathlib\n",
    "import zipfile\n",
    "import math\n",
    "import datetime\n",
    "import copy\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import interpolate\n",
    "from datetime import date, datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from pycel import ExcelCompiler\n",
    "from openpyxl import Workbook, load_workbook\n",
    "from statistics import mean\n",
    "from anytree import Node, find, findall\n",
    "from copy import copy, deepcopy\n",
    "from faker import Faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module 'logging' has no attribute 'config'\n"
     ]
    }
   ],
   "source": [
    "def timeit(func):\n",
    "    @wraps(func)\n",
    "    def timeit_wrapper(*args, **kwargs):\n",
    "        start_time = time.perf_counter()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.perf_counter()\n",
    "        total_time = end_time - start_time\n",
    "        print(f'Function {func.__name__}{args} {kwargs} Took {total_time:.4f} seconds')\n",
    "        return result\n",
    "    return timeit_wrapper\n",
    "\n",
    "# Manage logging system\n",
    "try:\n",
    "    logging.config.dictConfig({\n",
    "    'version': 1,\n",
    "    'disable_existing_loggers': False,\n",
    "    'formatters': {\n",
    "        'console': {\n",
    "            'format': '%(name)-12s %(levelname)-8s %(message)s'\n",
    "        },\n",
    "        'file': {\n",
    "            'format': '%(asctime)s %(name)-12s %(levelname)-8s %(message)s'\n",
    "        }\n",
    "    },\n",
    "    'handlers': {\n",
    "        'console': {\n",
    "            'class': 'logging.StreamHandler',\n",
    "            'formatter': 'console'\n",
    "        },\n",
    "        'file': {\n",
    "            'level': 'DEBUG',\n",
    "            'class': 'logging.FileHandler',\n",
    "            'formatter': 'file',\n",
    "            'filename': './logs/log.log'\n",
    "        }\n",
    "    },\n",
    "    'loggers': {\n",
    "        '': {\n",
    "            'level': 'DEBUG',\n",
    "            'handlers': ['console', 'file']\n",
    "        }\n",
    "    }\n",
    "})\n",
    "    os.makedirs('./logs', exist_ok=True)\n",
    "    logger = logging.getLogger(__name__)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "def rejectXlsFile(fn):\n",
    "    \"\"\"\n",
    "    Check if a given file name is valid for processing.\n",
    "\n",
    "    Args:\n",
    "        fn (str): The file name to be checked.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the file name is invalid, False if the file name is valid.\n",
    "\n",
    "    Example:\n",
    "        >>> file_name = \"example.xlsx\"\n",
    "        >>> result = rejectXlsFile(file_name)\n",
    "        >>> print(result)\n",
    "        False\n",
    "\n",
    "        >>> file_name = \".hidden.xlsx\"\n",
    "        >>> result = rejectXlsFile(file_name)\n",
    "        >>> print(result)\n",
    "        True\n",
    "    \"\"\"\n",
    "    if fn.startswith(\".\") or fn.startswith(InputAnalyzer.DELIMITER_SHEET_UNFOLLOW) or not fn.endswith('.xlsx'):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def reject_file(file_path):\n",
    "    \"\"\"\n",
    "    Check if a given file path is valid for processing.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path of the file to be checked.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the file path is invalid, False if the file path is valid.\n",
    "    \"\"\"\n",
    "    fn = os.path.basename(file_path)\n",
    "    if rejectXlsFile(fn):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def folder_zip(folderPath, zip_fn):\n",
    "    \"\"\"\n",
    "    Create a zip file of a given folder.\n",
    "\n",
    "    Args:\n",
    "        folderPath (str): The path of the folder to be zipped.\n",
    "        zip_fn (str): The filename of the generated zip file.\n",
    "\n",
    "    Returns:\n",
    "        str: The path of the generated zip file.\n",
    "    \"\"\"\n",
    "    directory = pathlib.Path(folderPath)\n",
    "    destination = f\"{directory.parent.absolute()}/{zip_fn}.zip\"\n",
    "\n",
    "    with zipfile.ZipFile(destination, mode=\"w\") as archive:\n",
    "        for file_path in directory.iterdir():\n",
    "            if reject_file(file_path):\n",
    "                continue\n",
    "            archive.write(file_path, arcname=file_path.name)\n",
    "    return destination\n",
    "\n",
    "\"\"\"\n",
    "The `InputAnalyzer` class is responsible for analyzing and processing data from an Excel worksheet. \n",
    "It can identify different types of sheets (operation, constant, summary, and curves) and extract relevant information from each type. \n",
    "It can also perform interpolation on curves and store the results.\n",
    "\n",
    "Main functionalities:\n",
    "- Identify and load different types of sheets (operation, constant, summary, and curves)\n",
    "- Extract metadata, points, curves, constants, summary, and operations from the sheet\n",
    "- Perform interpolation on curves\n",
    "- Add new curves, constants, summary, and operations to the analyzer\n",
    "\n",
    "Methods:\n",
    "- loadSheet(): Loads and analyzes the sheet, extracting relevant information based on the sheet type\n",
    "- addCurve(specification_name, value, unit, interpolation): Adds a new curve to the analyzer\n",
    "- addConstant(name, value, unit): Adds a new constant to the analyzer\n",
    "- addSummary(name, value, unit): Adds a new summary to the analyzer\n",
    "- addOperation(name, operation, unit): Adds a new operation to the analyzer\n",
    "- getCurveByName(name): Retrieves a curve by its name\n",
    "- getConstantByName(name): Retrieves a constant by its name\n",
    "- getSummaryByName(name): Retrieves a summary by its name\n",
    "- getOperationByName(name): Retrieves an operation by its name\n",
    "- getCategory(): Retrieves the category metadata of the sheet\n",
    "\n",
    "Fields:\n",
    "- BASE_ELEMENTS_ROW: The row number where the base elements are located\n",
    "- UNIT_ROW: The row number where the units are located\n",
    "- CURVE: The row number where the curve interpolations are located\n",
    "- METADATA_COL: The column letter where the metadata is located\n",
    "- POINT_N_COL: The column letter where the point numbers are located\n",
    "- DATE_COL: The column letter where the dates are located\n",
    "- PRODUCT_NAME: The metadata name for the product type\n",
    "- PRODUCT_PARENT: The metadata name for the product subtype\n",
    "- CATEGORY: The metadata name for the category\n",
    "- DELIMITER_SHEET_UNFOLLOW: The delimiter used to skip sheets\n",
    "- CONSTANT_SHEETNAME: The name of the constant sheet\n",
    "- SUMMARY_SHEETNAME: The name of the summary sheet\n",
    "- OPERATION_SHEETNAME: The name of the operation sheet\n",
    "- evaluator: An instance of the ExcelCompiler class for evaluating Excel formulas\n",
    "- sheet_name: The name of the sheet being analyzed\n",
    "- ws: The worksheet object being analyzed\n",
    "- curves: A list of dictionaries representing the curves in the sheet\n",
    "- points: A list of dictionaries representing the points in the sheet\n",
    "- metadatas: A dictionary representing the metadata in the sheet\n",
    "- operations: A dictionary representing the operations in the sheet\n",
    "- constants: A dictionary representing the constants in the sheet\n",
    "- summary: A list of dictionaries representing the summary in the sheet\n",
    "- fake: An instance of the Faker class for generating fake data\n",
    "\"\"\"\n",
    "class InputAnalyzer:\n",
    "    BASE_ELEMENTS_ROW = 17 # Location of base's elements\n",
    "    UNIT_ROW = 18 # Location of units\n",
    "    CURVE = 19 # Location of Curve's interpolations\n",
    "    METADATA_COL = \"A\"\n",
    "    POINT_N_COL = \"B\"\n",
    "    DATE_COL = \"D\"\n",
    "    PRODUCT_NAME = \"Product-Type\"\n",
    "    PRODUCT_PARENT = \"SubType\"\n",
    "    CATEGORY = \"Category\"\n",
    "    DELIMITER_SHEET_UNFOLLOW = \"_\"\n",
    "\n",
    "    CONSTANT_SHEETNAME = \"Constants\"\n",
    "    SUMMARY_SHEETNAME = \"Summary\" \n",
    "    OPERATION_SHEETNAME = \"operation\"\n",
    "\n",
    "    def __init__(self, ws, sheet_name, path) -> None:\n",
    "        self.evaluator = ExcelCompiler(filename=path)\n",
    "        self.sheet_name = sheet_name\n",
    "        self.ws = ws\n",
    "\n",
    "        self.curves = []\n",
    "        self.points = []\n",
    "        self.metadatas = {}\n",
    "        self.operations = {}\n",
    "        self.constants = {}\n",
    "        self.summary = []\n",
    "        self.fake = Faker()\n",
    "    \n",
    "    ### Util's functions\n",
    "\n",
    "    def log_interp1d(self, xx, yy, kind='linear', small_value=1e-10):\n",
    "        \"\"\"\n",
    "        Return the log interpolation on 1 dimension\n",
    "\n",
    "        Perform logarithmic interpolation on one-dimensional data.\n",
    "\n",
    "        Parameters:\n",
    "        xx (array): The x values of the data points.\n",
    "        yy (array): The y values of the data points.\n",
    "        kind (string, optional): The type of interpolation to perform. Defaults to 'linear'.\n",
    "        small_value (float, optional): A small value used to adjust the y values to avoid taking the logarithm of zero. Defaults to 1e-10.\n",
    "\n",
    "        Returns:\n",
    "        log_interp (lambda function): A lambda function that can be used to interpolate new y values based on the given x and y values.\n",
    "        \"\"\"\n",
    "        yy_adjusted = np.maximum(yy, small_value)\n",
    "        logx = np.log10(xx)\n",
    "        logy = np.log10(yy_adjusted)\n",
    "        lin_interp = interpolate.interp1d(logx, logy, kind=kind, fill_value=\"extrapolate\")\n",
    "        log_interp = lambda zz: np.power(10.0, lin_interp(np.log10(zz)))\n",
    "        return log_interp\n",
    "\n",
    "    def evaluate(self, cell):\n",
    "        \"\"\"\n",
    "        Return the evaluation's value of a given cell (rounded by 3)\n",
    "\n",
    "        Args:\n",
    "            cell (str): The cell reference in the Excel sheet (e.g., \"A1\").\n",
    "\n",
    "        Returns:\n",
    "            float: The evaluation value of the given cell, rounded to three decimal places.\n",
    "        \"\"\"\n",
    "        eval = self.evaluator.evaluate(self.sheet_name+\"!\"+cell.coordinate)\n",
    "        if isinstance(eval, float):\n",
    "            eval = round(eval, 3)\n",
    "        return eval\n",
    "    \n",
    "    def clean_string(self, text):\n",
    "        return str(text).replace(\"\\n\", \"\").replace(\"\\t\", \"\").lstrip()\n",
    "\n",
    "    ### 4 Sheet types\n",
    "\n",
    "    def isOperationSheet(self):\n",
    "        if self.OPERATION_SHEETNAME.lower() in self.sheet_name.lower():\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def isConstantSheet(self):\n",
    "        if self.CONSTANT_SHEETNAME.lower() in self.sheet_name.lower():\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def isSummarySheet(self):\n",
    "        if self.SUMMARY_SHEETNAME.lower() in self.sheet_name.lower():\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def isCurvesSheet(self):\n",
    "        if self.curves != [] and self.points != []:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    # Generator's functions\n",
    "\n",
    "    def _generatePointsWithDates(self):\n",
    "            \"\"\"\n",
    "            Return a dictionary of points with their associated dates.\n",
    "\n",
    "            This method collects the row number, point number, and date for each point in the worksheet.\n",
    "            It filters out any points that do not have a date.\n",
    "            If there are at least two points with dates, it performs linear interpolation to calculate the dates for the remaining points.\n",
    "            If there are fewer than two points with dates, it populates the missing dates based on a specified granularity.\n",
    "\n",
    "            Returns:\n",
    "            points_with_dates (dict): A dictionary containing the row number, point number, and date for each point in the worksheet.\n",
    "            \"\"\"\n",
    "\n",
    "            points = [\n",
    "                {\"row\": point.row, \"point_n\": self.evaluate(point), \"date\": self.ws[self.DATE_COL+str(point.row)].value } \n",
    "                for point in self.ws[self.POINT_N_COL] \n",
    "                if point.value is not None and (isinstance(point.value, (int, float)) or (isinstance(point.value, str) and point.value.startswith(\"=\")))\n",
    "            ]\n",
    "        \n",
    "            valid_points = [ pt for pt in points if pt[\"date\"] is not None ]\n",
    "            # Check if exist at least 2 dates in points\n",
    "            if len(valid_points) >= 2:\n",
    "                x = list(range(len(valid_points)))\n",
    "                try:\n",
    "                    y = list(map(datetime.datetime.timestamp, [pt[\"date\"] for pt in valid_points]))\n",
    "                except Exception as e:\n",
    "                    raise e\n",
    "                interp1d = interpolate.interp1d(x, y, fill_value=\"extrapolate\") \n",
    "                interpolated_timestamps = interp1d(x)\n",
    "                for pt, interpolated_timestamp in zip(valid_points, interpolated_timestamps):\n",
    "                    pt[\"date\"] = datetime.datetime.fromtimestamp(interpolated_timestamp)\n",
    "                for pt, interpolated_timestamp in zip(points, interpolated_timestamps):\n",
    "                    if pt[\"date\"] is None:\n",
    "                        pt[\"date\"] = datetime.datetime.fromtimestamp(interpolated_timestamp)\n",
    "                return points\n",
    "            else:\n",
    "                return self._populateByFrequency(points)\n",
    "\n",
    "    def _generateCurves(self):\n",
    "        \"\"\"\n",
    "        Return a sorted (by ASC) dict (column, curve, unit, interpolation) at BASE_ELEMENTS_ROW for a given sheetname\n",
    "        Ignore the firsts 2 elements because they always not belong to Curves\n",
    "        \"\"\"\n",
    "        return sorted([{\n",
    "            \"column\": be.column, \n",
    "            \"curve_name\": self.clean_string(be.value),\n",
    "            \"values\": None,\n",
    "            \"unit\": self.ws.cell(row=self.UNIT_ROW, column=be.column).value, \n",
    "            \"interpolation\": self.ws.cell(row=self.CURVE, column=be.column).value\n",
    "        } for be in self.ws[self.BASE_ELEMENTS_ROW] if be.value is not None][2:], key=lambda x: x[\"column\"])\n",
    "\n",
    "    def _generateMetaData(self):\n",
    "        \"\"\"\n",
    "        Return array of tuples (row_id, metadata_name, metadata_value) for a given sheetname\n",
    "        \"\"\"\n",
    "        return {self.clean_string(cell.value): self.ws['B'][cell.row-1].value \n",
    "            for cell in self.ws[self.METADATA_COL] \n",
    "            if (cell.value is not None and self.ws['B'][cell.row-1].value is not None and cell.row < self.BASE_ELEMENTS_ROW)}\n",
    "\n",
    "    def _generateConstants(self):\n",
    "        \"\"\"\n",
    "        Return all global constant in the sheet\n",
    "        \"\"\"\n",
    "        compositions = [(cmp.row, cmp.value) for cmp in self.ws[\"A\"] if cmp.value is not None]\n",
    "\n",
    "        result = {}\n",
    "        for index, cmp in enumerate(compositions):\n",
    "            tmp = []            \n",
    "            if(index != len(compositions)-1):\n",
    "                last_row = compositions[index+1][0]-1\n",
    "            else:\n",
    "                last_row = len(self.ws[\"B\"])\n",
    "\n",
    "            for x in range(cmp[0]+1, last_row):\n",
    "                if self.ws[\"B\"+str(x)].value is not None:\n",
    "                    tmp.append({\n",
    "                        \"constant_name\": self.clean_string(self.ws[\"B\"+str(x)].value),\n",
    "                        \"value\": self.evaluate(self.ws[\"C\"+str(x)]),\n",
    "                        \"unit\": self.evaluate(self.ws[\"D\"+str(x)])\n",
    "                    })\n",
    "            \n",
    "            result[cmp[1]] = tmp\n",
    "\n",
    "        return result\n",
    "\n",
    "    def _generateSummary(self):\n",
    "        for composition in self.ws[\"A\"]:\n",
    "            if composition.value is not None and self.ws.cell(row=composition.row, column=composition.column+1).value is not None:\n",
    "                self.addSummary(composition.value, self.ws.cell(row=composition.row, column=composition.column+1).value, self.ws.cell(row=composition.row, column=composition.column+2).value)\n",
    "\n",
    "    def _generateOperations(self):\n",
    "        \"\"\"\n",
    "        Return operations\n",
    "        \"\"\"\n",
    "        items = [(it.row, it.value) for it in self.ws[\"A\"] if it.value is not None]\n",
    "\n",
    "        result = {}\n",
    "        for index, fcn in enumerate(items):\n",
    "            tmp = []            \n",
    "            if(index != len(items)-1):\n",
    "                last_row = items[index+1][0]-1\n",
    "            else:\n",
    "                last_row = len(self.ws[\"B\"])\n",
    "\n",
    "            for x in range(fcn[0]+1, last_row):\n",
    "                if self.ws[\"B\"+str(x)].value is not None:\n",
    "                    tmp.append({\n",
    "                        \"operation_name\": self.clean_string(self.ws[\"B\"+str(x)].value),\n",
    "                        \"operation\": self.evaluate(self.ws[\"C\"+str(x)]),\n",
    "                        \"unit\": self.clean_string(self.ws[\"D\"+str(x)].value) \n",
    "                    })\n",
    "            \n",
    "            result[fcn[1]] = tmp\n",
    "\n",
    "        return result\n",
    "\n",
    "    def _populateByFrequency(self, points, granularity=\"year\", X=1):\n",
    "        \"\"\"\n",
    "        Populates the given list of points with interpolated dates based on a reference date.\n",
    "\n",
    "        Parameters:\n",
    "        - points (list): A list of dictionaries where each dictionary has a \"date\" key.\n",
    "                        The list should have at least one point with a non-null date.\n",
    "        - granularity (str): The unit for interpolation. Supported values are \"year\", \"month\", \n",
    "                        \"day\", \"hour\", and \"minute\".\n",
    "        - X (int): The multiplier for the granularity.\n",
    "\n",
    "        The function will find the first non-null date in the points list and use it as a reference.\n",
    "        It will then populate missing dates in the list based on the given granularity and multiplier.\n",
    "\n",
    "        Returns:\n",
    "        - None: The function modifies the input list in-place.\n",
    "        \"\"\"\n",
    "\n",
    "        # Mapping granularities to their respective relativedelta functions and random generators using faker\n",
    "        granularity_map = {\n",
    "            \"year\": lambda base_date, diff: base_date + relativedelta(years=random.randint(1, diff)),\n",
    "            \"month\": lambda base_date, diff: base_date + relativedelta(months=random.randint(1, diff)),\n",
    "            \"day\": lambda base_date, diff: base_date + timedelta(days=random.randint(1, diff)),\n",
    "            \"hour\": lambda base_date, diff: base_date + timedelta(hours=random.randint(1, diff)),\n",
    "            \"minute\": lambda base_date, diff: base_date + timedelta(minutes=random.randint(1, diff))\n",
    "        }\n",
    "\n",
    "        # Create the reference date as the first one found\n",
    "        ref_date = next(({\"index\": index, \"date\": point[\"date\"]} for index, point in enumerate(points) if point[\"date\"]), None)\n",
    "\n",
    "        if ref_date:\n",
    "            for index, point in enumerate(points):\n",
    "                if point[\"date\"] is None:\n",
    "                    point[\"date\"] = granularity_map[granularity](ref_date, X)\n",
    "        \n",
    "        return points\n",
    "\n",
    "    def _getValuesByCurve(self, curve):\n",
    "        result = []\n",
    "        value = None\n",
    "        for point in self.points:\n",
    "            cell = self.ws.cell(row=point[\"row\"], column=curve[\"column\"])\n",
    "            if cell.value is not None and cell.value != \"#REF!\":\n",
    "                if isinstance(cell.value, str):\n",
    "                    if cell.value.startswith(\"=\"):\n",
    "                        value = self.evaluator.evaluate(self.sheet_name+\"!\"+cell.coordinate)\n",
    "                    if \"%\" in cell.value:\n",
    "                        value = float(cell.value.replace(\"%\", \"\"))/100\n",
    "                elif isinstance(cell.value, float) or isinstance(cell.value, int):\n",
    "                    value = cell.value\n",
    "                result.append({\n",
    "                    \"row\": point[\"row\"],\n",
    "                    \"value\": value\n",
    "                })\n",
    "        return result \n",
    "\n",
    "    def _evaluateInterpolation(self, curve):\n",
    "        result = []\n",
    "        values = self._getValuesByCurve(curve)\n",
    "        \n",
    "        if (curve[\"interpolation\"] == \"CONST\" and len(values) > 0) or (curve[\"interpolation\"] is None and len(values) == 1):\n",
    "            result = [next(item[\"value\"] for item in values if item[\"value\"] is not None)] * len(self.points)\n",
    "        elif len(values) >= 2:\n",
    "            xs, ys = [v[\"row\"] for v in values], [v[\"value\"] for v in values]           \n",
    "            if curve[\"interpolation\"] == \"LOG\":\n",
    "                interp1d = self.log_interp1d(xs, ys)\n",
    "            else:\n",
    "                interp1d = interpolate.interp1d(xs,ys, fill_value=\"extrapolate\")\n",
    "\n",
    "            # Add result of interpolation for each point\n",
    "            result = [float(interp1d(point[\"row\"])) for point in self.points]\n",
    "        return result\n",
    "\n",
    "    # Init Functions\n",
    "\n",
    "    def loadSheet(self):\n",
    "        \"\"\"\n",
    "            Return JSON storage of the input\n",
    "        \"\"\"\n",
    "\n",
    "        if self.sheet_name.startswith(self.DELIMITER_SHEET_UNFOLLOW):\n",
    "            logger.info(f\"loadSheet('{self.sheet_name}') : SKIPPED\")\n",
    "            return False\n",
    "\n",
    "        if self.isOperationSheet():\n",
    "            logger.info(f\"loadSheet('{self.sheet_name}') : Formulas_Sheet\")\n",
    "            self.operations = self._generateOperations()\n",
    "            return True\n",
    "\n",
    "        if self.isConstantSheet():\n",
    "            logger.info(f\"loadSheet('{self.sheet_name}') : Constants_Sheet\")\n",
    "            self.constants = self._generateConstants()\n",
    "            return True\n",
    "\n",
    "        if self.isSummarySheet():\n",
    "            logger.info(f\"loadSheet('{self.sheet_name}') : Summary_Sheet\")\n",
    "            self._generateSummary()\n",
    "            return True\n",
    "\n",
    "        logger.info(f\"loadSheet('{self.sheet_name}') : Curves_Sheet\")\n",
    "\n",
    "        # Get all elements in worksheet\n",
    "        self.metadatas = self._generateMetaData()\n",
    "        self.points = self._generatePointsWithDates()\n",
    "        self.curves = self._generateCurves()\n",
    "        \n",
    "        if self.isCurvesSheet() and self.metadatas == {}:\n",
    "            raise Exception(\"Metadatas are missing...{}\".format(self.sheet_name))\n",
    "\n",
    "        # Interpolate values  \n",
    "        for curve in self.curves:\n",
    "            curve[\"values\"] = self._evaluateInterpolation(curve)       \n",
    "        \n",
    "        return True\n",
    "    \n",
    "    # Add Functions\n",
    "\n",
    "    def addCurve(self, specifcation_name, value, unit, interpolation=\"CONST\"):\n",
    "        \"\"\"\n",
    "        Add new Curve to the analyzer, if curve exists we do nothing\n",
    "        \"\"\"\n",
    "\n",
    "        if self.getCurveByName(specifcation_name) is not None:\n",
    "            return None\n",
    "\n",
    "        next_free_column = self.curves[-1][\"column\"]+1\n",
    "\n",
    "        self.curves.append({\n",
    "            \"column\": next_free_column,\n",
    "            \"curve_name\": self.clean_string(specifcation_name),\n",
    "            \"values\": [value] * len(self.points), \n",
    "            \"unit\": unit if unit is not None else \"\",\n",
    "            \"interpolation\": interpolation\n",
    "        })\n",
    "    \n",
    "    def addSummary(self, summary_name, value, unit):\n",
    "        if self.getSummaryByName(summary_name) is not None:\n",
    "            return None\n",
    "\n",
    "        self.summary.append({\n",
    "            \"summary_name\": self.clean_string(summary_name),\n",
    "            \"summary_value\": value,\n",
    "            \"unit\": unit if unit is not None else \"\"\n",
    "        })\n",
    "\n",
    "    # Access Functions\n",
    "\n",
    "    def getCurveByName(self, name):\n",
    "        res = next((item for item in self.curves if self.clean_string(item[\"curve_name\"].lower()) == self.clean_string(name.lower())), None)\n",
    "        if res is not None :\n",
    "            res[\"specificiation_name\"] = self.clean_string(res[\"curve_name\"])\n",
    "        return res\n",
    "        \n",
    "    def getConstantByName(self, name):\n",
    "        result = iter([item for item in list(self.constants.values())[0] if self.clean_string(item[\"constant_name\"].lower()) == self.clean_string(name.lower())])\n",
    "        return next(result, None)\n",
    "    \n",
    "    def getConstantByCategoryAndName(self, category, name):\n",
    "        if category in self.constants:\n",
    "            return next(iter([item for item in self.constants[category] if self.clean_string(item[\"constant_name\"].lower()) == self.clean_string(name.lower())]), None)\n",
    "\n",
    "    def getSummaryByName(self, name):\n",
    "        result = iter([item for item in self.summary if item[\"summary_name\"].lower() == name.lower()])\n",
    "        return next(result, None)\n",
    "\n",
    "    def getOperationByName(self, name):\n",
    "        result = iter([item for item in self.operations if item[\"operation_name\"].lower() == name.lower()])\n",
    "        return next(result, None)                        \n",
    "\n",
    "    def getCategory(self):\n",
    "        if self.CATEGORY in self.metadatas:\n",
    "            return str(self.metadatas[self.CATEGORY])\n",
    "        return None\n",
    "\n",
    "\"\"\"\n",
    "The `SheetTree` class is responsible for creating a tree structure to organize and analyze sheets in Excel workbooks.\n",
    "\n",
    "Attributes:\n",
    "    path (str): The path to the folder containing the Excel workbooks.\n",
    "    root (Node): The root node of the formula tree.\n",
    "    all_sheet (dict): A dictionary with the file names as keys and a list of sheet analyzers as values.\n",
    "    operation_sheets (list): A list of sheet analyzers for the operation sheets.\n",
    "\"\"\"\n",
    "class SheetTree:\n",
    "    def __init__(self, path) -> None:\n",
    "        \"\"\"\n",
    "        Initializes a new instance of the SheetTree class.\n",
    "        \n",
    "        Args:\n",
    "            path (str): The path to the folder containing the Excel workbooks.\n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "        \n",
    "        self.root = Node(\"root\")\n",
    "        self.root.name = \"Summary\"\n",
    "        self.root.categories = {}\n",
    "\n",
    "        self.all_sheet = None\n",
    "        self.operation_sheets = []\n",
    "\n",
    "    def readAllSheetsFromFolder(self, folder):\n",
    "        \"\"\"\n",
    "        Reads all the sheets from a folder and returns a dictionary with the file names as keys and a list of sheet analyzers as values.\n",
    "        \n",
    "        Args:\n",
    "            folder (str): The path to the folder containing the Excel workbooks.\n",
    "        \n",
    "        Returns:\n",
    "            dict: A dictionary with the file names as keys and a list of sheet analyzers as values.\n",
    "        \"\"\"\n",
    "        result = {}\n",
    "\n",
    "        # Load all workbooks\n",
    "        all_files = next(os.walk(folder), (None, None, []))[2]\n",
    "        all_files = [ fn for fn in all_files if not rejectXlsFile(fn) ]\n",
    "        all_wks = { file: load_workbook(folder +'/'+ file) for file in all_files }\n",
    "        \n",
    "        # Create dict with file: {sheetname: analyzer}\n",
    "        for file, wb in all_wks.items():\n",
    "            result[file] = []\n",
    "            for sheet_name in wb.sheetnames:\n",
    "                if sheet_name.startswith(InputAnalyzer.DELIMITER_SHEET_UNFOLLOW):\n",
    "                    logger.info(f\"Sheet('{sheet_name}') : SKIPPED\")\n",
    "                    continue\n",
    "                analyzer = InputAnalyzer(wb[sheet_name], sheet_name, folder + '/' + file)\n",
    "                if analyzer.loadSheet():\n",
    "                    result[file].append((sheet_name, analyzer,))\n",
    "\n",
    "        return result\n",
    "\n",
    "    def mapSheetsToFormulaTree(self, path=None):\n",
    "        \"\"\"\n",
    "        Maps the sheets to the formula tree structure.\n",
    "        \n",
    "        Args:\n",
    "            path (str, optional): The path to the folder containing the Excel workbooks. If not provided, uses the default path.\n",
    "        \"\"\"\n",
    "        if not path:\n",
    "            path = self.path\n",
    "        nodes = []\n",
    "        self.all_sheet = self.readAllSheetsFromFolder(path)\n",
    "        # Create all nodes\n",
    "        for _file, wbSheets in self.all_sheet.items():\n",
    "            for sheet_name, analyzer in wbSheets:\n",
    "                if analyzer.isOperationSheet():\n",
    "                    self.operation_sheets.append(analyzer)\n",
    "                    continue\n",
    "            \n",
    "                if analyzer.isConstantSheet():\n",
    "                    Node(sheet_name, analyzer=analyzer, parent=self.root)\n",
    "                    continue\n",
    "\n",
    "                if analyzer.isSummarySheet():\n",
    "                    if not hasattr(self.root, \"analyzer\"):\n",
    "                        self.root.analyzer = analyzer\n",
    "                    else:\n",
    "                        # Delete summary value with same key that root_summary\n",
    "                        for root_summary in self.root.analyzer.summary:\n",
    "                            for summary in analyzer.summary:\n",
    "                                if root_summary[\"summary_name\"].lower() == summary[\"summary_name\"].lower():\n",
    "                                    del summary\n",
    "                        # Merge summaries values\n",
    "                        for summary in analyzer.summary:\n",
    "                            self.root.analyzer.summary.append(summary)\n",
    "                                                        \n",
    "                    continue\n",
    "\n",
    "                if analyzer.metadatas == {}:\n",
    "                    continue\n",
    "                \n",
    "                # last Case is a \"Curves\" sheet\n",
    "                # Get parent name if exists\n",
    "                parentName = analyzer.metadatas[analyzer.PRODUCT_PARENT] if (analyzer.PRODUCT_PARENT in analyzer.metadatas) else None\n",
    "                    \n",
    "                productType = analyzer.metadatas[analyzer.PRODUCT_NAME]\n",
    "                node = Node(productType, analyzer=analyzer)\n",
    "                \n",
    "                # Get and add category to self.root.categories if exist\n",
    "                category = analyzer.getCategory()\n",
    "                if category is not None:\n",
    "                    self.root.categories[category.lower()] = category.upper()+\":\"\n",
    "                    node.category = category.lower()\n",
    "                                            \n",
    "                nodes.append( (parentName, productType, node ) )\n",
    "        \n",
    "        # Add parent for all nodes\n",
    "        for element in nodes:\n",
    "            if element[0] is None: # if no parentName\n",
    "                element[2].parent = self.root\n",
    "            else:\n",
    "                i = [i for i, v in enumerate(nodes) if v[1] == element[0] and element[2].category == v[2].category]\n",
    "                if i != []:\n",
    "                    element[2].parent = nodes[i[0]][2]\n",
    "\n",
    "def findNode(treeRoot, category, scope, verbose=False):\n",
    "    \"\"\"\n",
    "    Find the first node in a tree structure based on its category and scope.\n",
    "\n",
    "    Args:\n",
    "        treeRoot (Node): The root node of the tree structure.\n",
    "        category (str): The category of the node to find.\n",
    "        scope (str): The scope of the node to find.\n",
    "        verbose (bool, optional): Whether to log errors if multiple nodes are found. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        Node: The first matching node found in the tree based on the given category and scope.\n",
    "\n",
    "    Raises:\n",
    "        Exception: If the node with the given category and scope is not found in the tree.\n",
    "    \"\"\"\n",
    "    catCode = category.lower()\n",
    "    nodes = None\n",
    "    if scope:\n",
    "        nodes = findall(treeRoot, lambda node: node.name.lower() == catCode and hasattr(node, 'category') and node.category == scope)\n",
    "        if not nodes and scope == \"root\":\n",
    "            nodes = findall(treeRoot, lambda node: node.name.lower() == catCode and not hasattr(node, 'category'))\n",
    "        if len(nodes)>1 and verbose:\n",
    "            logger.error(f\"!!! nodes_according_to_category({catCode}) Scope({scope}).length()>1\")\n",
    "    if not nodes:\n",
    "        nodes = findall(treeRoot, lambda node: node.name.lower() == catCode) \n",
    "        if not nodes:\n",
    "            raise Exception(f\"Cannot find sheet '{catCode}' in the tree... with Scope '{scope}'\")\n",
    "\n",
    "    node = nodes[0] if nodes else nodes\n",
    "    return node\n",
    "\n",
    "\"\"\"\n",
    "The `SheetInterpreter` class is responsible for interpreting and evaluating formulas in Excel workbooks. \n",
    "It replaces variables and functions in the formulas with their corresponding values and then evaluates the formulas to obtain the final results.\n",
    "\n",
    "Main functionalities:\n",
    "- Replaces variables and functions in formulas with their corresponding values\n",
    "- Evaluates the formulas to obtain the final results\n",
    "- Updates the summary and curves sheets in the Excel workbooks with the evaluated results\n",
    "\n",
    "Methods:\n",
    "- __init__(self, folder): Initializes a new instance of the SheetInterpreter class with the specified folder path.\n",
    "- findOperation(self, category, operation_name): Finds an operation by its category and operation name.\n",
    "- convertFilter(self, value, unit, filter): Converts a value based on a filter.\n",
    "- replaceOneVarByValue(self, word, default_node, category, scope): Replaces a variable in a formula with its corresponding value.\n",
    "- replaceAllVarsByValue(self, opStr, default_node, category, scope): Replaces all variables in a formula with their corresponding values.\n",
    "- replaceFcnByVar(self, opStr, category, scope): Replaces functions in a formula with their corresponding values.\n",
    "- mapOperationValues(self, list_operations, category, scope): Maps the values in a list of operations by replacing variables and functions with their corresponding values.\n",
    "- operationParser(self): Parses the operations by replacing functions with variables and mapping the values.\n",
    "- evaluate(self): Evaluates the formulas by replacing variables and functions with their values and updating the summary and curves sheets.\n",
    "\n",
    "Fields:\n",
    "- tree: The SheetTree object that represents the tree structure of the Excel workbooks.\n",
    "- node_categories: A list of the categories of the nodes in the tree.\n",
    "- operations: A dictionary that stores the evaluated operations categorized by node category.\n",
    "\"\"\"\n",
    "class SheetInterpreter:\n",
    "\n",
    "    FILTERS_DISPATCH = {\n",
    "        \"date\" : {\n",
    "            \"year\" : lambda x: x.year,\n",
    "            \"month\": lambda x: x.month,\n",
    "            \"day\": lambda x: x.day\n",
    "        }\n",
    "    }\n",
    "\n",
    "    FCN_EXPR = '\\{[ \\_\\(\\)\\-\\|\\.a-zA-Z0-9]+\\}'\n",
    "    VAR_EXPR = '\\[[ \\_\\(\\)\\|\\-\\+a-zA-Z0-9\\.]+\\]'\n",
    "\n",
    "    def __init__(self, folder) -> None:\n",
    "        self.tree = SheetTree(folder)\n",
    "        self.tree.mapSheetsToFormulaTree()\n",
    "        self.node_categories = list(self.tree.root.categories.keys()) # list(map(lambda x: x.lower(), list(self.tree.root.categories.keys())))\n",
    "        self.operations = {cat: [] for cat in self.node_categories}\n",
    "        self.operations[\"root\"] = []\n",
    "    \n",
    "    # Utils functions\n",
    "\n",
    "    def findOperation(self, category, operation_name):\n",
    "        \"\"\"\n",
    "        Find an operation by it category and it operation_name \n",
    "        \"\"\"\n",
    "        for analyzer in self.tree.operation_sheets:\n",
    "            for analyzer_category, operations in analyzer.operations.items():\n",
    "                if analyzer_category.lower() == category.lower():\n",
    "                    return next((operation for operation in operations if operation[\"operation_name\"].lower() == operation_name.lower()), None)\n",
    "        return None\n",
    "\n",
    "    def convertFilter(self, value, unit, filter):\n",
    "        \"\"\"\n",
    "        Convert value by it filter\n",
    "        Ex : datetime(01/01/2022)|year = 2022\n",
    "        \"\"\"\n",
    "        try:\n",
    "            func = self.FILTERS_DISPATCH[unit.lower()][filter.lower()]\n",
    "            value = func(value)\n",
    "        except: pass\n",
    "        return value\n",
    "\n",
    "    # Functions to search and replace variables and functions\n",
    "    \n",
    "    def replaceOneVarByValue(self, word, default_node, category, scope):\n",
    "        \"\"\"\n",
    "        Replace Word by his Variable Value in the according worksheet\n",
    "        \"\"\"\n",
    "\n",
    "        if word is None or category is None:\n",
    "            raise Exception(\"replaceOneVarByValue need all paramaters fill...\")\n",
    "        \n",
    "        correct_word = word.replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "        attr = correct_word.split('.')\n",
    "\n",
    "        if len(attr) == 1:\n",
    "            attr.insert(0, category)\n",
    "\n",
    "        if len(attr) > 1:\n",
    "            node = findNode(self.tree.root, attr[0], scope)\n",
    "            # nodes = findall(self.tree.root, lambda node: node.name.lower() == attr[0].lower()) \n",
    "\n",
    "            # if not nodes:\n",
    "            #     raise Exception(f\"Cannot find sheet '{attr[0]}' in the tree... with category '{category}'\")\n",
    "\n",
    "            # if len(nodes) > 1:\n",
    "            #     node = find(self.tree.root, lambda n: hasattr(n, \"category\") and n.category == dst and n.name.lower() == attr[0].lower())\n",
    "            #     if not node:\n",
    "            #         node = nodes[0]\n",
    "            # else:\n",
    "            #     node = nodes[0]\n",
    "        else:\n",
    "            node = default_node\n",
    "\n",
    "        # It is a constant\n",
    "        if len(attr) == 3 and node.analyzer.isConstantSheet():\n",
    "            constant = node.analyzer.getConstantByCategoryAndName(attr[1], attr[2])\n",
    "            if constant is not None:\n",
    "                return constant[\"value\"]\n",
    "            \n",
    "            return None\n",
    "\n",
    "        if node.analyzer.isSummarySheet():\n",
    "            cw = attr[1].split('|')\n",
    "\n",
    "            summary = node.analyzer.getSummaryByName(cw[0])\n",
    "\n",
    "            if summary:\n",
    "                if len(cw) == 2:\n",
    "                    return self.convertFilter(summary[\"summary_value\"], summary[\"unit\"], cw[1])\n",
    "                    \n",
    "                return summary[\"summary_value\"]\n",
    "            return None\n",
    "\n",
    "        if node.analyzer.isCurvesSheet():\n",
    "            spec = node.analyzer.getCurveByName(attr[1])\n",
    "            \n",
    "            if spec is not None:\n",
    "                if spec[\"interpolation\"] == \"CONST\":\n",
    "                    return spec[\"values\"][0]\n",
    "                else:\n",
    "                    # make an average of each interpolate's values \n",
    "                    return mean(spec[\"values\"])\n",
    "            else:\n",
    "                raise Exception('Error: replaceOneVarByValue()', word, node, category, scope, attr, node.analyzer.curves)\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def replaceAllVarsByValue(self, opStr, default_node, category, scope):\n",
    "        # Replace first all vars [] by value in result\n",
    "        for m in re.finditer(self.VAR_EXPR, opStr):\n",
    "            opStr = opStr.replace(m.group(0), str(self.replaceOneVarByValue(m.group(0), default_node, category, scope)))\n",
    "        return opStr\n",
    "\n",
    "    def replaceFcnByVar(self, opStr, category, scope):\n",
    "        \"\"\"\n",
    "            Replace all fcn {} by value\n",
    "        \"\"\"\n",
    "        matches = re.finditer(self.FCN_EXPR, opStr)\n",
    "        while matches is not None:\n",
    "            for match in matches:\n",
    "                according_op = None\n",
    "                wks = None\n",
    "\n",
    "                fcn_name = match.group(0).replace(\"{\", \"\").replace(\"}\", \"\").strip()\n",
    "                attr = fcn_name.split('.')\n",
    "\n",
    "                # if operation exist in list operation, add the value of it in it\n",
    "                if len(attr) > 2:\n",
    "                    raise Exception(\"unknown function syntax for:\", attr)\n",
    "                \n",
    "                if len(attr) == 1:\n",
    "                    attr.insert(0, category)\n",
    "                \n",
    "                according_op = self.findOperation(attr[0], attr[1])\n",
    "\n",
    "                if according_op is not None:\n",
    "                    related_nodes = findall(self.tree.root, lambda n: n.name.lower() == attr[0].lower())\n",
    "                else:\n",
    "                    raise Exception(\"prb :\", attr, match.group(0), fcn_name)\n",
    "                \n",
    "                if according_op is not None and related_nodes != ():\n",
    "                    for wks in related_nodes:                            \n",
    "                        # Transform all {} in children by interpretable {}\n",
    "                        accStr = according_op[\"operation\"]\n",
    "                        for m in re.finditer(self.FCN_EXPR, accStr):\n",
    "                            rpl = m.group(0).replace(\"{\", \"\").replace(\"}\", \"\").strip()\n",
    "\n",
    "                            if len(rpl.split(\".\")) == 1:\n",
    "                                accStr = accStr.replace(m.group(0), \"{\"+attr[0]+\".\"+rpl+\"}\")\n",
    "\n",
    "                        accStr = self.replaceAllVarsByValue(accStr, wks, attr[0], scope)\n",
    "                        \n",
    "                        opStr = opStr.replace(match.group(0), \"(\"+ accStr+ \")\")\n",
    "                        try:\n",
    "                            opStr = str(round(eval(opStr), 10))\n",
    "                        except:\n",
    "                            pass\n",
    "                else:\n",
    "                    raise Exception(\"A problem is in :\", attr, match.group(0))    \n",
    "\n",
    "            if re.search(self.FCN_EXPR, opStr) is not None:\n",
    "                matches = re.finditer(self.FCN_EXPR, opStr)\n",
    "            else:\n",
    "                matches = None\n",
    "        try:\n",
    "            opStr = str(round(eval(opStr), 10))\n",
    "        except:\n",
    "            pass\n",
    "        return opStr\n",
    "\n",
    "    def mapOperationValues(self, list_operations, category, scope):\n",
    "        try:\n",
    "            default_node = findNode(self.tree.root, category, scope, verbose=False)\n",
    "\n",
    "            if default_node:                  \n",
    "                copy_operations = copy.deepcopy(list_operations)    \n",
    "                \n",
    "                for index, op in enumerate(copy_operations):                            \n",
    "                    if op[\"operation\"] is None:\n",
    "                        raise Exception(\"Operation can't be null :\", op)\n",
    "            \n",
    "                    opStr = self.replaceAllVarsByValue(op[\"operation\"], default_node, category, scope)\n",
    "                    op[\"operation\"] = self.replaceFcnByVar(opStr, category, scope)\n",
    "                    \n",
    "                    op[\"node_category\"] = default_node\n",
    "\n",
    "                    copy_operations[index] = op\n",
    "                    \n",
    "                return copy_operations\n",
    "        except Exception as e:\n",
    "            logger.error(e)\n",
    "            print(e)\n",
    "            raise e\n",
    "\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    def operationParser(self):\n",
    "        \"\"\"\n",
    "        Replace all Formula {} by Var [] while it's present in string of all operations \n",
    "        \"\"\"\n",
    "        for analyzer in self.tree.operation_sheets:\n",
    "            for category, l_operations in analyzer.operations.items():\n",
    "\n",
    "                if category is None or l_operations is None or not isinstance(category, str):\n",
    "                    raise Exception('ReplaceFcnByVar needs category and operations')\n",
    "\n",
    "                # Map values in self.operations\n",
    "                for dst, stored_operations in self.operations.items():\n",
    "                    values = self.mapOperationValues(l_operations, category, dst)\n",
    "\n",
    "                    if values:\n",
    "                        stored_operations.append(values) \n",
    "\n",
    "    # Render functions\n",
    "    def evaluate(self):\n",
    "        \"\"\"\n",
    "        Replace all [] Expression by their Values to be evaluate next\n",
    "        \"\"\"\n",
    "        \n",
    "        # Search all {} operations and replace by []\n",
    "        self.operationParser()\n",
    "\n",
    "        # Eval all operations\n",
    "        for dst, list_operations in self.operations.items():\n",
    "            for operations in list_operations:\n",
    "                    for operation in operations:\n",
    "                        try:\n",
    "                            # Attention si l'user met rm -rf * par exemple !!\n",
    "                            # logging.log(operation[\"operation\"])\n",
    "                            operation[\"operation\"] = round(eval(str(operation[\"operation\"])), 4)\n",
    "                            # logging.log(operation[\"operation\"])\n",
    "                            if operation[\"node_category\"].analyzer.isSummarySheet():\n",
    "                                operation[\"node_category\"].analyzer.addSummary(operation[\"operation_name\"], operation[\"operation\"], operation[\"unit\"])\n",
    "                            elif operation[\"node_category\"].analyzer.isCurvesSheet():\n",
    "                                operation[\"node_category\"].analyzer.addCurve(operation[\"operation_name\"], operation[\"operation\"], operation[\"unit\"], \"CONST\")\n",
    "                        except Exception as e:\n",
    "                            raise Exception(\"Error for evaluation of operations\", operation, e)\n",
    "\n",
    "\"\"\"\n",
    "The `OutputAnalyzer` class is responsible for analyzing and manipulating data in an Excel sheet. \n",
    "It provides methods for converting values based on filters, formatting values based on units, copying cell styles, inserting data according to transformer functions, unmerging cells, and finding and replacing annotated values with curve values.\n",
    "\n",
    "Methods:\n",
    "    - `__init__(self, wb, sheet_name, path, interpreter)`: Initializes an instance of `OutputAnalyzer` with the given workbook, sheet name, file path, and interpreter.\n",
    "    - `convertFilter(self, value, unit, filter)`: Converts a value based on a filter and unit.\n",
    "    - `formatByUnit(self, val, unit)`: Formats a value based on its unit.\n",
    "    - `copyCellStyle(self, cell, new_cell)`: Copies the style of a cell to a new cell.\n",
    "    - `isInterpretable(self, value)`: Checks if a value is interpretable.\n",
    "    - `insertTransformer(self, cell, for_already_insert)`: Inserts data according to a transformer function.\n",
    "    - `unmergeCell(self, cell)`: Unmerges a cell.\n",
    "    - `findAndReplaceAnnotateValues(self)`: Finds and replaces annotated values with curve values.\n",
    "    - `save(self, path)`: Saves the modified workbook to the specified path.\n",
    "\n",
    "Fields:\n",
    "    - `EXPRESSION`: Regular expression pattern for matching variable expressions in output cells.\n",
    "    - `FUNCTION`: Dictionary mapping function names to their corresponding keywords.\n",
    "    - `FUNCTION_TRANSFORMER`: Dictionary mapping function names to their corresponding transformer functions.\n",
    "    - `FILTERS_DISPATCH`: Dictionary mapping filter categories to their corresponding dispatch functions.\n",
    "    - `UNIT_FORMATS`: Dictionary mapping unit names to their corresponding formatting functions.\n",
    "    - `evaluator`: Instance of `ExcelCompiler` for evaluating Excel formulas.\n",
    "    - `sheet_name`: Name of the sheet being analyzed.\n",
    "    - `wb`: Workbook object being analyzed.\n",
    "    - `ws`: Worksheet object being analyzed.\n",
    "    - `tree`: Tree object representing the Excel file structure.\n",
    "    - `interpreter`: Instance of `ExcelInterpreter` for interpreting Excel files.\n",
    "\"\"\"\n",
    "class OutputAnalyzer:\n",
    "\n",
    "    EXPRESSION = '\\[[ \\_\\(\\)\\|\\-\\+a-zA-Z0-9\\.]+\\]' # expression of a var in output's cell\n",
    "    \n",
    "    FUNCTION = {\n",
    "        \"for\": \"FOR:\",\n",
    "    }\n",
    "\n",
    "    FUNCTION_TRANSFORMER = {\n",
    "        'for': [\"INDEX\", \"DATEPOINT\"]\n",
    "    }\n",
    "\n",
    "    FILTERS_DISPATCH = {\n",
    "        \"category\": {}\n",
    "    }\n",
    "\n",
    "    UNIT_FORMATS = {\n",
    "        \"date\" : lambda x: x.strftime('%Y-%m-%d'),\n",
    "        \"$\": lambda x: '{:,.2f}'.format(x),\n",
    "        \"\": lambda x: '{:,.2f}'.format(x),\n",
    "        \"cost\": lambda x: '{:,.2f}'.format(x),\n",
    "        \"%\": lambda x: \"{:.2%}\".format(x)\n",
    "    }   \n",
    "\n",
    "    def __init__(self, wb, sheet_name, path, interpreter) -> None:\n",
    "        self.evaluator = ExcelCompiler(filename=path)\n",
    "        self.sheet_name = sheet_name\n",
    "        self.wb = wb\n",
    "        self.ws = self.wb[sheet_name]\n",
    "        self.tree = interpreter.tree\n",
    "        self.interpreter = interpreter\n",
    "        self.FILTERS_DISPATCH[\"category\"] = {item: lambda x: x for item in self.tree.root.categories}\n",
    "\n",
    "    def convertFilter(self, value, unit, filter):\n",
    "        \"\"\"\n",
    "        Convert value by it filter\n",
    "        Ex : 01/01/2022|year = 2022\n",
    "        \"\"\"\n",
    "        if unit.lower() in self.FILTERS_DISPATCH and filter.lower() in self.FILTERS_DISPATCH[unit]:\n",
    "            return self.FILTERS_DISPATCH[unit.lower()][filter.lower()](value)\n",
    "        return value\n",
    "\n",
    "    def formatByUnit(self, val, unit):\n",
    "        \"\"\"\n",
    "        Format val according to his unit by UNIT_FORMATS function\n",
    "        \"\"\"\n",
    "        if unit is not None and val != \"\" and unit != \"\" and unit in list(self.UNIT_FORMATS.keys()):\n",
    "            try:\n",
    "                return copy.deepcopy(self.UNIT_FORMATS[unit](val))\n",
    "            except Exception as e:\n",
    "                raise Exception(\"Unit problem : \", e, unit, val)\n",
    "        return val\n",
    "\n",
    "    def copyCellStyle(self, cell, new_cell):\n",
    "        \"\"\"\n",
    "        Return new_cell with the style of cell\n",
    "        \"\"\"\n",
    "        if cell is not None and cell.has_style and new_cell is not None:\n",
    "            try:\n",
    "                new_cell.font = copy.copy(cell.font)\n",
    "                new_cell.border = copy.copy(cell.border)\n",
    "                new_cell.fill = copy.copy(cell.fill)\n",
    "                new_cell.number_format = copy.copy(cell.number_format)\n",
    "                new_cell.protection = copy.copy(cell.protection)\n",
    "                new_cell.alignment = copy.copy(cell.alignment)\n",
    "            except Exception as e:\n",
    "                raise Exception(e)\n",
    "\n",
    "        return new_cell\n",
    "\n",
    "    def isInterpretable(self, value):\n",
    "        \"\"\"\n",
    "        Check if it's an interpretable value and return true if it is else false\n",
    "        \"\"\"\n",
    "        if value is None or not isinstance(value, str) or value == \"\" or value == \" \" or value == \"$\":\n",
    "            return False\n",
    "        \n",
    "        # Check if value start with one value of self.FUNCTION\n",
    "        valid_func = next(iter([True for key_func, value_func in self.FUNCTION.items() if value.startswith(value_func)]), False)\n",
    "        \n",
    "        try:\n",
    "           re.search(value, self.EXPRESSION)\n",
    "        except:\n",
    "            raise Exception(value, self.EXPRESSION)\n",
    "             \n",
    "        if re.search(value, self.EXPRESSION) or valid_func:\n",
    "            return True\n",
    "            \n",
    "        return False\n",
    "\n",
    "    def _randomize_date(self, date):\n",
    "        # Gnrer un nouveau mois et un nouveau jour alatoires\n",
    "        random_month = random.randint(1, 12)\n",
    "        # Gnrer un jour valide pour le mois\n",
    "        if random_month == 2:  # Fvrier\n",
    "            # Tenir compte des annes bissextiles pour fvrier\n",
    "            if (date.year % 4 == 0 and date.year % 100 != 0) or (date.year % 400 == 0):\n",
    "                random_day = random.randint(1, 29)\n",
    "            else:\n",
    "                random_day = random.randint(1, 28)\n",
    "        elif random_month in [4, 6, 9, 11]:  # Avril, Juin, Septembre, Novembre\n",
    "            random_day = random.randint(1, 30)\n",
    "        else:  # Les autres mois\n",
    "            random_day = random.randint(1, 31)\n",
    "        \n",
    "        # Crer une nouvelle date avec l'anne originale, le nouveau mois et le nouveau jour\n",
    "        new_date = date.replace(month=random_month, day=random_day)\n",
    "        return new_date\n",
    "\n",
    "    def insertTransformer(self, cell, for_already_insert):\n",
    "        \"\"\"\n",
    "        Insert data according to the transformer function and return True if it's done else False\n",
    "        \"\"\"\n",
    "\n",
    "        if isinstance(cell.value, str) and cell.value.startswith(self.FUNCTION[\"for\"]):\n",
    "            l = [item for item in self.FUNCTION_TRANSFORMER[\"for\"] if cell.value.endswith(item)]\n",
    "            if l != []:\n",
    "                l = l[0]\n",
    "                \n",
    "                start = self.tree.root.analyzer.getSummaryByName(\"Start\")[\"summary_value\"]\n",
    "                end = self.tree.root.analyzer.getSummaryByName(\"End\")[\"summary_value\"]\n",
    "                delta = relativedelta(end, start)\n",
    "                \n",
    "                # Add date if DATEPOINT else add index\n",
    "                values = list(map(lambda x: self._randomize_date(start + relativedelta(years=x)) if l == \"DATEPOINT\" else x+1, [item for item in range(0, delta.years+1)]))\n",
    "                unit = \"date\" if l == \"DATEPOINT\" else None\n",
    "\n",
    "                if not for_already_insert:\n",
    "                    for i in range(1, len(values)):\n",
    "                        self.ws.insert_rows(cell.row+i)\n",
    "                \n",
    "                self.ws.cell(row=cell.row, column=cell.column).value = self.formatByUnit(values[0], unit)\n",
    "                for i in range(1, len(values)):\n",
    "                    self.ws.cell(row=cell.row+i, column=cell.column).value = self.formatByUnit(values[i], unit)\n",
    "                    self.copyCellStyle(cell, self.ws.cell(row=cell.row+i, column=cell.column))\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def unmergeCell(self, cell):\n",
    "        # Check if cell is MergedCell and unmerge it\n",
    "        for mergecells in self.ws.merged_cells.ranges:\n",
    "            pass\n",
    "\n",
    "    def findAndReplaceAnnotateValues(self):\n",
    "        \"\"\"\n",
    "        Find and replace all annotate's values by their curve's value\n",
    "        \"\"\"\n",
    "        \n",
    "        for row in self.ws:\n",
    "            for_already_insert = False\n",
    "            for cell in row:\n",
    "                # add new row if not already did\n",
    "                if self.isInterpretable(cell.value):\n",
    "                    \n",
    "                    if self.insertTransformer(cell, for_already_insert):\n",
    "                        for_already_insert = True\n",
    "                        continue\n",
    "\n",
    "                    matches = re.finditer(self.EXPRESSION, cell.value)\n",
    "                    for match in matches:\n",
    "                        node = None\n",
    "                        m = match.group(0).replace(\"[\", \"\").replace(\"]\", \"\").strip()\n",
    "                        attr = m.split(\".\")\n",
    "\n",
    "                        if len(attr) > 1:\n",
    "                            # Check if filter exist\n",
    "                            filter = attr[1].split(\"|\")\n",
    "                            attr[1] = filter[0]\n",
    "\n",
    "                            node = findNode(self.tree.root, attr[0], filter[1].lower() if len(filter) > 1 else None, verbose=False)\n",
    "                         \n",
    "                            if node is not None:\n",
    "                                data = None\n",
    "                                val = {}\n",
    "\n",
    "                                if node.analyzer.isCurvesSheet():\n",
    "                                    data = node.analyzer.getCurveByName(attr[1])\n",
    "                                                        \n",
    "                                    if data is not None:\n",
    "                                        # Interprete FOR directive according to val\n",
    "                                        if cell.value.startswith(self.FUNCTION[\"for\"]) and [item for item in self.FUNCTION_TRANSFORMER[\"for\"] if cell.value.endswith(item)] == []:\n",
    "                                            start = self.tree.root.analyzer.getSummaryByName(\"Start\")[\"summary_value\"]\n",
    "                                            end = self.tree.root.analyzer.getSummaryByName(\"End\")[\"summary_value\"]\n",
    "                                            delta = relativedelta(end, start)\n",
    "                                            nb_points = delta.years\n",
    "\n",
    "                                            # if for not previously added and insert necessary row\n",
    "                                            if not for_already_insert:\n",
    "                                                for_already_insert = True\n",
    "                                                for i in range(1, nb_points):\n",
    "                                                    self.ws.insert_rows(cell.row+i)\n",
    "                                            \n",
    "                                            # Add values to each cell\n",
    "                                            for i in range(0, nb_points):\n",
    "                                                self.ws.cell(row=cell.row+i, column=cell.column).value = self.formatByUnit(data[\"values\"][i], data[\"unit\"])\n",
    "                                                self.copyCellStyle(cell, self.ws.cell(row=cell.row+i, column=cell.column))\n",
    "                                            continue\n",
    "                                        \n",
    "                                        # Get data value\n",
    "                                        if data[\"interpolation\"] == \"CONST\":\n",
    "                                            try:\n",
    "                                                val = data[\"values\"][0]\n",
    "                                            except:\n",
    "                                                raise Exception(\"No value found for : \", data)\n",
    "                                        else:\n",
    "                                            try:\n",
    "                                                val = mean(data[\"values\"])\n",
    "                                            except:\n",
    "                                                raise Exception(\"Can't do a mean of value for \", data)\n",
    "\n",
    "                                if node.analyzer.isConstantSheet() and len(attr) > 2:\n",
    "                                    data = node.analyzer.getConstantByCategoryAndName(attr[1], attr[2])\n",
    "                                    val = data[\"value\"] if data is not None else None                    \n",
    "\n",
    "                                if node.analyzer.isSummarySheet():\n",
    "                                    data = node.analyzer.getSummaryByName(attr[1])\n",
    "                                    val = data[\"summary_value\"] if data is not None else None\n",
    "\n",
    "                                val = self.formatByUnit(val, data[\"unit\"]) if data is not None and \"unit\" in data else val\n",
    "                                \n",
    "                                cell.value = val if val != {} and val is not None else \"\"\n",
    "\n",
    "    def save(self, path):\n",
    "        self.wb.save(path)\n",
    "\n",
    "    \"\"\"\n",
    "    The `SheetOutputGenerator` class is responsible for generating the final output Excel file by analyzing and replacing variables in the output sheets based on the values obtained from the interpreter.\n",
    "\n",
    "    Args:\n",
    "        interpreter (SheetInterpreter): The interpreter object used to evaluate the input file.\n",
    "        output_path (str): The path to the output files.\n",
    "    \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "The SheetOutputGenerator class is responsible for generating the final output Excel file by replacing variables in the output sheets with their corresponding values obtained from the interpreter.\n",
    "\n",
    "Args:\n",
    "    interpreter (Interpreter): The interpreter object used to obtain the values for the variables in the output sheets.\n",
    "    output_path (str): The path to the output files.\n",
    "\n",
    "Attributes:\n",
    "    output_path (str): The path to the output files.\n",
    "    interpreter (Interpreter): The interpreter object used to obtain the values for the variables in the output sheets.\n",
    "    all_sheets (dict): A dictionary containing the analyzed output sheets for each output file.\n",
    "\"\"\"\n",
    "class SheetOutputGenerator:\n",
    "    \n",
    "    def __init__(self, interpreter, output_path):\n",
    "        \"\"\"\n",
    "        Initializes the SheetOutputGenerator object with the specified interpreter and output path.\n",
    "\n",
    "        Args:\n",
    "            interpreter (Interpreter): The interpreter object used to obtain the values for the variables in the output sheets.\n",
    "            output_path (str): The path to the output files.\n",
    "        \"\"\"\n",
    "        self.output_path = output_path\n",
    "        self.interpreter = interpreter\n",
    "        self.all_sheets = None\n",
    "\n",
    "    def analyzeAllOutputSheet(self):\n",
    "        \"\"\"\n",
    "        Analyzes all output sheets by creating an OutputAnalyzer object for each sheet in each output file.\n",
    "        Sets self.all_sheets to a dictionary containing the analyzed output sheets for each output file.\n",
    "        \"\"\"\n",
    "        all_files = next(os.walk(self.output_path), (None, None, []))[2]\n",
    "        all_wks = {file: load_workbook(self.output_path + file) for file in all_files if file.endswith('.xlsx')}\n",
    "        \n",
    "        self.all_sheets = {}\n",
    "        for file, wb in all_wks.items():\n",
    "            sheetsDic = {\n",
    "                sheet_name: OutputAnalyzer(wb, sheet_name, self.output_path + file, self.interpreter)\n",
    "                for sheet_name in all_wks[file].sheetnames\n",
    "            }\n",
    "            self.all_sheets[file] = sheetsDic\n",
    "\n",
    "    def generate(self, folder, zip_fn):\n",
    "        \"\"\"\n",
    "        Generates the final output Excel file by replacing variables in the output sheets with their corresponding values obtained from the interpreter.\n",
    "\n",
    "        Args:\n",
    "            folder (str): The folder to save the generated output files.\n",
    "            zip_fn (str): The filename of the generated zip file.\n",
    "\n",
    "        Returns:\n",
    "            str: The path to the generated zip file.\n",
    "        \"\"\"\n",
    "        from pathlib import Path\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "        count = 0\n",
    "        for fPath, sheets in self.all_sheets.items():\n",
    "            count +=1\n",
    "            fn = Path(fPath).stem\n",
    "            for sheet_name, analyzer in sheets.items():\n",
    "                analyzer.findAndReplaceAnnotateValues()\n",
    "                analyzer.save(f\"{folder}/{fn}.xlsx\")\n",
    "\n",
    "        return folder_zip(folder, zip_fn)\n",
    "\n",
    "\"\"\"\n",
    "This class is responsible for checking the format of a file. \n",
    "It loads the file using the `load_workbook` function from the `openpyxl` library and iterates over each sheet in the workbook. \n",
    "For each sheet, it creates an instance of the `InputAnalyzer` class to analyze the sheet. \n",
    "If the sheet is a summary sheet, it stores the summary data. \n",
    "If the sheet is a constant or operation sheet, it adds the sheet name to the list of non-accepted files. \n",
    "Finally, it saves the modified workbook.\n",
    "\n",
    "Fields:\n",
    "- path: The path of the file to be checked.\n",
    "- summary: The summary data extracted from the summary sheet.\n",
    "- non_accepted: A list of sheet names that are not accepted (constant or operation sheets).\n",
    "- wb: The `Workbook` object representing the loaded workbook.\n",
    "\"\"\"\n",
    "class FileChecker:\n",
    "\n",
    "    def __init__(self, path) -> None:\n",
    "        \"\"\"\n",
    "        Initializes the `FileChecker` object with the path of the file to be checked.\n",
    "\n",
    "        Args:\n",
    "        - path: The path of the file to be checked.\n",
    "        \"\"\"\n",
    "        self.path = path\n",
    "        self.summary = None\n",
    "        self.non_accepted = []\n",
    "        self.wb = None\n",
    "\n",
    "    def checkForSpecFormat(self):\n",
    "        \"\"\"\n",
    "        Checks the format of the file. Loads the file using `load_workbook` function, iterates over each sheet, analyzes each sheet using `InputAnalyzer` class, stores the summary data if the sheet is a summary sheet, adds the sheet name to the list of non-accepted files if the sheet is a constant or operation sheet, and saves the modified workbook.\n",
    "\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        self.wb = load_workbook(self.path)\n",
    "        for sheet_name in self.wb.sheetnames:\n",
    "            analyzer = InputAnalyzer(self.wb[sheet_name], sheet_name, self.path)\n",
    "            if analyzer.loadSheet():\n",
    "                if analyzer.isSummarySheet():\n",
    "                    self.summary = analyzer.summary\n",
    "                    self.wb.remove(self.wb[sheet_name])\n",
    "            \n",
    "                if analyzer.isConstantSheet() or analyzer.isOperationSheet():\n",
    "                    self.non_accepted.append(sheet_name)\n",
    "                    self.wb.remove(self.wb[sheet_name])         \n",
    "        self.wb.save(self.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-980aac88dc5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSheetOutputGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmedia\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/dataset/data/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmedia\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/dataset/models/output/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/result/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"archive\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-7c75975f0cfe>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, folder, zip_fn)\u001b[0m\n\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1279\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msheets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_sheets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1280\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1281\u001b[0m             \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "current = Path(os.getcwd())\n",
    "media = str(current.parent.parent.absolute())\n",
    "\n",
    "output = SheetOutputGenerator(media+\"/dataset/data/\", media+\"/dataset/models/output/\")\n",
    "output.generate(os.getcwd()+\"/result/\", \"archive\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(2.)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "d1 = np.datetime64('2019-01-01')\n",
    "d2 = np.datetime64('2019-01-03')\n",
    "xp = np.array([d1, d2])\n",
    "yp = np.array([1, 3])\n",
    "x = np.datetime64('2019-01-02')\n",
    "f = interp1d(xp.astype('float64'), yp)\n",
    "f(x.astype('float64'))\n",
    "f(x)  # now error appears"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
